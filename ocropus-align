#!/usr/bin/python

################################################################
### Align transcriptions with lattices.
###
### This is rather complex and messy legacy code.  Look
### for a newer version of this.
################################################################

import sys,os,re,glob,math,glob,signal,traceback,sqlite3
import matplotlib
if "DISPLAY" not in os.environ: matplotlib.use("AGG")
else: matplotlib.use("GTK")
from scipy.ndimage import interpolation,measurements
from pylab import *
from optparse import OptionParser
from multiprocessing import Pool
import ocrolib
from ocrolib import number_of_processors,fstutils,die,docproc
from scipy import stats
from ocrolib import dbhelper,ocroio,ocrofst

signal.signal(signal.SIGINT,lambda *args:sys.exit(1))

import argparse
parser = argparse.ArgumentParser(description = """
%prog [-s gt] [-l langmod] [options] file.fst ...

    Align each file.fst with language model and output the result into
    file.cseg.png, file.costs, and file.txt.  With -s gt, writes the
    results into file.cseg.gt.png, file.gt.costs, and file.gt.txt 
    instead.

%prog [-s gt] [-g extension] [options] *.fst

    Align with groundtruth files.  For each x.fst, looks for the ground truth
    in x.extension

%prog [-s gt] [-p] [options] *.gt.txt

    Align with page-level ground truth.  For each page.gt.txt, looks in
    page/??????.png for the image data.

Aligns recognition lattices (stored in .fst files) with language models and/or
ground truth.  If -g extension is given, each foo.fst file is aligned with a
corresponding foo.extension file.  

Language models and ground truth files may be given either as FST files or 
text files.  If they are given as text files, an FST is constructed by using
the fstutils.add_line_to_fst function.

""")


parser.add_argument("-l","--langmod",help="language model",default=None)
parser.add_argument("-x","--extract",help="extract characters",default=None)
parser.add_argument("-X","--noextract",help="don't actually write files",action="store_true")
parser.add_argument("-L","--ligatures",help="output ligatures in aligned text",action="store_true")
parser.add_argument("-B","--beam",help="size of beam",type=int,default=1000)
parser.add_argument("-N","--noligatures",help="don't expand ligature notation in transcriptions",action="store_true")
parser.add_argument("-g","--gt",help="extension for ground truth",default=None)
parser.add_argument("-p","--pagegt",help="arguments are page ground truth",action="store_true")
parser.add_argument("-s","--suffix",help="output suffix for writing result",default=None)
parser.add_argument("-O","--overwrite",help="overwrite outputs",action="store_true")
parser.add_argument("-P","--perc",help="percentile for reporting statistics",type=float,default=90.0)
parser.add_argument("-M","--maxperc",help="maximum cost at percentile",type=float,default=2.0)
parser.add_argument("-A","--maxavg",help="maximum average cost",type=float,default=3.0)
parser.add_argument("-a","--aligner",help="choose the aligner to use",default="=ocrolib.fstutils.DefaultAligner()")
parser.add_argument("-Y","--debug_cls",help="select classes for debugging",default=None)
parser.add_argument("-Q","--parallel",type=int,default=number_of_processors(),help="number of parallel processes to use")
parser.add_argument("-c","--cont",help="continue on error",action="store_true")
parser.add_argument("-E","--showerrs",help="show errors",action="store_true")
parser.add_argument("-D","--Display",help="display",action="store_true")
parser.add_argument('--dgrid',default=15,help="grid size for display")
parser.add_argument('-r','--parameter',default=[],nargs='*',help="other aligner parameter (repeat if desired)")
parser.add_argument("args",default=[],nargs='*',help="input lines)")
options = parser.parse_args()
args = options.args

if len(args)==0:
    parser.print_help()
    sys.exit(0)

if options.showerrs:
    options.parallel=0

if options.extract is not None and os.path.exists(options.extract):
    print "output file already exists:",options.extract
    sys.exit(1)

# Database handling is a bit tricky because of concurrency.
# First create the database and update the columns if necessary.
# Then close the db descriptor.  Reopen it in each multiprocessing
# subtask if necessary.

db = None

if options.extract:
    db = sqlite3.connect(options.extract,timeout=600.0)
    dbhelper.charcolumns(db,"chars")
    db.commit()
    db.close()
    db = None

def dbopen():
    global db
    if db is not None: return
    if options.extract:
        db = sqlite3.connect(options.extract,timeout=600.0)
        db.row_factory = dbhelper.DbRow
        db.text_factory = sqlite3.OptimizedUnicode
        db.execute("pragma synchronous=0")
        db.commit()

################################################################
### Construct a finite state transducer for alignment between
### a given transcription and a lattice.
################################################################

import codecs
import openfst
from ocrolib.fstutils import explode_transcription,epsilon,space,sigma,add_between,optimize_openfst,openfst2ocrofst

class AlignerMixin:
    def getOcroFst(self):
        fst = self.getFst()
        return openfst2ocrofst(fst)
    def fstForLines(self,lines):
        self.startFst()
        for line in lines:
            self.addTranscription(line)
        return self.getFst()
    def ocroFstForLines(self,lines):
        self.startFst()
        for line in lines:
            self.addTranscription(line)
        return self.getOcroFst()
    def fstForFile(self,file):
        try:
            with codecs.open(file,"r","utf-8") as stream:
                return self.fstForLines(stream.readlines())
        except UnicodeDecodeError,e:
            raise Exception("bad unicode in "+file)
    def ocroFstForFile(self,file):
        try:
            with codecs.open(file,"r","utf-8") as stream:
                return self.ocroFstForLines(stream.readlines())
        except UnicodeDecodeError,e:
            raise Exception("bad unicode in "+file)

common_segmentation_errors = [ "ff", "fi", "00", "st", "ry" ]

class DefaultAligner(AlignerMixin):
    def __init__(self,**kw):
        self.error="#"
        self.insert=""
        self.delete=""
        self.space_insert=5.0
        self.space_delete=5.0
        self.char_mismatch=8.0
        self.char_insert=2.0
        self.char_delete=20.0
        self.classifier_reject=None
        self.add_l2l=0.0
        self.add_c2l=0.0
        self.add_l2c=0.0
        self.rewrites = []
        self.combine = common_segmentation_errors
        self.combine_cost = 6.0
        self.lig = ligatures.lig
        self.optimize = 0
        self.sigout = True
        self.multi = 3
        self.multi_cost = 5.0
    def startFst(self):
        """Initializing a new FST."""
        self.fst = openfst.StdVectorFst()
    def getFst(self):
        """After adding all the lines, get the resulting FST."""
        fst = self.fst
        self.fst = None
        fst = optimize_openfst(fst,optimize=self.optimize)
        return fst
    def explodeTranscription(self,line):
        """Take a transcription given as a string and turn it into a list."""
        line = line.strip()
        line = re.sub(r'[ ~\t\n]+',' ',line)
        return explode_transcription(line)
    def addTranscription(self,line):
        """Add a text line as a path through the aligner."""
        line = self.explodeTranscription(line)
        self.addCodes(line)
    def addCodes(self,line,accept=0.0):
        """Given a list of "codes" (characters or character sequences),
        encode them as a line in an FST.  Call this multiple times to encode
        multiple lists."""
        fst = self.fst
        lig = self.lig
        state = fst.Start()
        if state<0:
            state = fst.AddState()
            fst.SetStart(state)
        states = [state]
        for i in range(len(line)):
            states.append(fst.AddState())
        for i in range(len(line)):
            s = line[i]
            c = lig.ord(s)
            start = states[i]
            next = states[i+1]

            # FIXME split this up into several loops/methods

            # space is special (since we use separate skip/insertion self)

            if s==" ":
                # space transition
                fst.AddArc(start,space,space,0.0,next)
                fst.AddArc(next,space,space,0.0,next) 
                # space skip transition
                if self.space_delete is not None:
                    fst.AddArc(start,epsilon,space,self.space_delete,next)
                continue

            # insert characters or ligatures as single tokens

            if len(s)==1 or self.add_l2l is not None:
                assert c is not None,"ligature [%s] not found in ligature table"%s
                cost = 0.0 if len(s)==1 else self.add_l2l
                fst.AddArc(start,c,c,cost,next)
                if self.classifier_reject is not None:
                    fst.AddArc(start,lig.ord("~"),c,self.classifier_reject,next)

            # insert rewrites (s:gt with cost c)

            if self.rewrites is not None:
                for s,gt,c in self.rewrites:
                    add_between(fst,start,next,list(s),list(gt),c,lig=lig)

            # insert character combinations

            for q in self.combine:
                if tuple(q)==tuple(line[i:i+len(q)]):
                    if i+len(q)==len(line):
                        skip = states[i+len(q)]
                        l = lig.ord(q)
                        add_between(fst,start,skip,[sigma],[l],self.combine_cost,lig=lig)
                    else:
                        skip = states[i+len(q)+1]
                        nc = lig.ord(line[i+len(q)])
                        add_between(fst,start,skip,[sigma,nc],[lig.ord(q),nc],self.combine_cost,lig=lig)

            # FIXME replace the rest of the loops below with add_between as well

            # allow insertion of spaces with some cost

            if self.space_insert is not None:
                fst.AddArc(next,epsilon,space,self.space_insert,next)

            # allow insertion of a character relative to ground truth

            if self.char_insert is not None:
                fst.AddArc(start,sigma,lig.ord(self.insert),self.char_insert,start)

            # allow character mismatches

            if self.char_mismatch is not None:
                if self.sigout:
                    fst.AddArc(start,sigma,lig.ord(s),self.char_mismatch,next)
                else:
                    fst.AddArc(start,sigma,lig.ord(self.error),self.char_mismatch,next)

            # allow deletion of a character relative to ground truth

            if self.char_delete is not None:
                fst.AddArc(start,epsilon,lig.ord(self.delete),self.char_delete,next)

            # insert character-to-ligature

            if len(s)>1 and self.add_c2l is not None:
                add_between(fst,start,next,list(s),[s],self.add_c2l,lig=lig)


            # insert ligature-to-characters

            if self.add_l2c is not None:
                candidate = "".join(line[i:i+4])
                for s in ligatures.common_ligatures(candidate):
                    if len(s)<2 or i+len(s)>len(states): continue
                    add_between(fst,start,next,[s],list(s),self.add_l2c)

            # insert ligature-to-characters unconstrained

            if self.multi>0:
                # candidate = "".join(line[i:i+4])
                # print candidate
                for r in range(2,self.multi+1):
                    if len(candidate)<r: break
                    skip = states[i+r]
                    add_between(fst,start,skip,[sigma],[candidate[:r]],self.multi_cost,lig=lig)

            # make sure nobody messed up these variables
            assert start==states[i] and next==states[i+1]

        # also allow junk at the end

        if self.char_insert is not None:
            fst.AddArc(states[-1],sigma,lig.ord(self.insert),self.char_insert,states[-1])

        fst.SetFinal(states[-1],accept)

class UW3Aligner(DefaultAligner):
    def explodeTranscription(self,gt):
        gt = re.sub(r'\n',' ',gt)
        gt = re.sub(r'\\\^{(.*?)}','\1',gt)
        gt = re.sub(r'\\ast','*',gt)
        gt = re.sub(r'\\dagger','+',gt)
        gt = re.sub(r'\\[a-zA-Z]+','~',gt)
        gt = re.sub(r'\\_','',gt)
        gt = re.sub(r'[{}]','',gt)
        gt = re.sub(r'_+','~',gt)
        gt = re.sub(r'[ ~]+',' ',gt)
        gt = re.sub(r'^[ ~]*','',gt)
        gt = re.sub(r'[ ~]*$','',gt)
        return list(gt)

more_segmentation_errors = """
000 00 II IM La Th VL OC EX EP MP ME WM Ma Me
ac ai ak al all am an ar as be bo ca ch ci co ct
di dr ea ec ed ee er es ff fi fl fr ft gh gi gr gu hi il
in ir is ki li ll ma mi mm ni oc oo pe po re ri rin
rm rn ro r rs rt ru rv ry se sl so ss st 
ta te th ti to tr ts tt tu 
ul um un ur vi wi wn
a. c. e. m. n. t. z. A. C. E. K. L. M. N. R.
a, c, e, m, n, t, z, A, C, E, K, L, M, N, R,
a- b- e- d- g- m- n- o- p- u-
"T "W 'T 'W d" f" @@""".split()

class LenientAligner(DefaultAligner):
    def __init__(self,**kw):
        DefaultAligner.__init__(self)
        self.combine = more_segmentation_errors
        kw = common.set_params(self,kw)

class UW3LenientAligner(UW3Aligner):
    def __init__(self,**kw):
        UW3Aligner.__init__(self)
        self.combine = more_segmentation_errors
        kw = common.set_params(self,kw)

def make_line_fst(lines):
    aligner = LenientAligner()
    aligner.startFst()
    for text in lines:
        aligner.addTranscription(text)
    return aligner.getFst()

def load_text_file_as_fst(fname):
    aligner = LenientAligner()
    with open(fname) as stream:
        text = stream.read()
    aligner.startFst()
    aligner.addTranscription(text)
    return aligner.getFst()

################################################################
### take the output from a beam search across the alignment model
### and the lattice and find the correspondences
################################################################

from ocrolib import ligatures,rect_union,Record

def compute_alignment(lattice,rseg,lmodel,beam=1000,verbose=0,lig=ligatures.lig):
    """Given a lattice produced by a recognizer, a raw segmentation,
    and a language model, computes the best solution, the cseg, and
    the corresponding costs.  These are returned as Python data structures.
    The recognition lattice needs to have rseg's segment numbers as inputs
    (pairs of 16 bit numbers); SimpleGrouper produces such lattices."""

    v1,v2,ins,outs,costs = ocrofst.beam_search(lattice,lmodel,beam)

    # useful for debugging

    if 1:
        for i in range(len(v1)):
            print "@@@ %3d [%3d %3d] (%3d %3d) %6.2f"%(i,v1[i],v2[i],ins[i]>>16,ins[i]&0xffff,costs[i]),lig.chr(outs[i])

    assert len(ins)==len(outs)
    n = len(ins)

    # This is a little tricky because we need to deal with ligatures.
    # For any transition followed by epsilon transitions on the
    # output, we group all the segments of the epsilon transition with
    # the preceding non-epsilon transition.

    result_l = [""]
    costs_l = [0.0]
    segs = [(-1,-1)]

    i = 0
    while i<n:
        j = i+1
        start = ins[i]>>16
        end = ins[i]&0xffff
        cls = [outs[i]]
        # print "  %4d (%2d,%2d) %3d %s"%(i,start,end,outs[i],unichr(outs[i]))
        # while j<n and ((ins[j]==0 and outs[j]!=32) or outs[j]==0):
        while j<n and (outs[j]==0 or ins[j]==ins[i]):
            # print " +%4d (%2d,%2d) %3d %s"%(i,ins[j]>>16,ins[j]&0xffff,outs[j],unichr(outs[j]))
            if ins[j]!=0:
                start = min(start,ins[j]>>16)
                end = max(end,ins[j]&0xffff)
            if outs[j]!=0:
                cls.append(outs[j])
            j = j+1
        cls = "".join([lig.chr(x) for x in cls])
        if cls!="":
            result_l.append(cls)
            costs_l.append(sum(costs[i:j]))
            segs.append((start,end))
        i = j

    rseg_boxes = docproc.seg_boxes(rseg)

    # Now run through the segments and create a table that maps rseg
    # labels to the corresponding output element.

    assert len(result_l)==len(segs)
    assert len(costs_l)==len(segs)
    bboxes = []

    rmap = zeros(amax(rseg)+1,'i')
    for i in range(1,len(segs)):
        start,end = segs[i]
        if verbose: print i+1,start,end,"'%s'"%result[i],costs.at(i)
        if start==0 or end==0: continue
        rmap[start:end+1] = i
        bboxes.append(rect_union(rseg_boxes[start:end+1]))
    assert rmap[0]==0

    # Finally, to get the cseg, apply the rmap table from above.

    cseg = zeros(rseg.shape,'i')
    for i in range(cseg.shape[0]):
        for j in range(cseg.shape[1]):
            cseg[i,j] = rmap[rseg[i,j]]

    if 0:
        print len(rmap),rmap
        print len(segs),segs
        print len(result_l),result_l
        print len(costs_l),costs_l
        print amin(cseg),amax(cseg)

    # assert len(segs)==len(rmap) 
    assert len(segs)==len(result_l) 
    assert len(segs)==len(costs_l)
    return Record(
        # alignment output; these all have the same lengths
        output_l=result_l,
        segs=segs,
        costs=array(costs_l,'f'),
        # other convenient output representation
        output="".join(result_l),
        output_t=fstutils.implode_transcription(result_l),
        cost=sum(costs_l),
        # raw beam search output
        ins=ins,
        outs=outs,
        # segmentation images
        rseg=rseg,
        cseg=cseg,
        # the lattice
        lattice=lattice,
        # bounding boxes
        bboxes=bboxes,
        )

# We can potentially use different kinds of aligners; need an option to configure
# this.

# aligner = fstutils.DefaultAligner()
# aligner = ocrolib.load_component(options.aligner)
aligner = DefaultAligner()

for s in options.parameter:
    k,v = s.split("=",2)
    assert k in aligner.__dict__.keys(),"aligner %s does not have a parameter %s"%(aligner,k)
    try: v = int(v)
    except:
        try: v = float(v)
        except: pass
    setattr(aligner,k,v)

lfile = None
lfst = None

def safe_align1(t):
    try:
        align1(t)
    except:
        traceback.print_exc()
    return None

def align1(t):
    dbopen()
    global lfile,lfst
    (fname,lmodel) = t
    ocrolib.fcleanup(fname,options.suffix,["txt","costs"])

    try:
        fst = ocrofst.OcroFST()
        fst.load(ocrolib.ffind(fname,"fst"))
        rseg = ocroio.read_line_segmentation(ocrolib.ffind(fname,"rseg"))

        if lmodel!=lfile:
            lfile = lmodel
            nolig = not options.noligatures
            if lmodel.endswith(".fst"):
                lfst = ocrofst.OcroFST().load(lmodel)
            else:
                lfst = aligner.ocroFstForFile(lmodel)
                lfst.save("_aligner.fst")

        assert lfst is not None
        
        r = compute_alignment(fst,rseg,lfst)

        cseg = r.cseg
        assert amin(cseg)==0,"amin(cseg)!=0 (%d,%d)"%(amin(cseg),amax(cseg))
        costs = r.costs

        # first work on the list output; here, one list element should
        # correspond to each cost
        result = r.output_l
        assert len(result)==len(costs),\
            "output length %d differs from cost length %d"%(len(result),len(costs))
        assert amax(r.cseg)<len(result),\
            "amax(r.cseg) %d not consistent with output length %d"%(amax(r.cseg),len(r.output_l))

        # if there are spaces at the end, trim them (since they will never have a corresponding cseg)
        while len(result)>0 and result[-1]==" ":
            result = result[:-1]
            costs = costs[:-1]
        if amax(r.cseg)+1!=len(result):
            # Note: we can't distinguish deletions at the end from other misalignment problems;
            # these fields are probably OK, but for now we just skip them.  Later there will
            # be an option to output them anyway.
            print "%s: segmentation and transcript don't align; probably deletion at end"%fname
            if options.showerrs:
                ion()
                axis = subplot(111)
                axis.imshow(r.cseg,cmap=cm.gist_stern) # cmap=cm.flag
                objects = measurements.find_objects(r.cseg)
                xs = [0.5*(p[1].start+p[1].stop) if p is not None else None for p in objects]
                xs = [0]+xs
                h,w = r.cseg.shape
                for i in range(min(len(result),len(xs))):
                    # print "[%s]"%result
                    if xs[i] is None: continue
                    axis.text(xs[i],h,result[i],color="red",size=10)
                for i in range(min(len(result),len(xs)),len(result)):
                    print "extra",i,result[i]
                show()
                raw_input()
            return

        if options.ligatures:
            # print result
            result = fstutils.implode_transcription(result)
        else:
            result = "".join(result)

        perc = stats.scoreatpercentile(costs,options.perc)
        avg = mean(costs)
        skip = (perc > options.maxperc or avg>options.maxavg)

        if len(r.output)==0:
            print "* %s: [no output]"%(fname,)
            return
        else:
            print "%-1s %s: %5.2f %5.2f: %s"%("*" if skip else " ",fname,perc,avg,result)
            if skip: return

        if not options.noextract:
            cseg_file = ocrolib.fvariant(fname,"cseg",options.suffix)
            if not options.overwrite:
                if os.path.exists(cseg_file): die("%s: already exists",cseg_file)
            ocrolib.write_line_segmentation(cseg_file,cseg)
            ocrolib.write_text(ocrolib.fvariant(fname,"txt",options.suffix),result)
            with ocrolib.fopen(fname,"costs",options.suffix,mode="w") as stream:
                for i in range(len(costs)):
                    stream.write("%d %g\n"%(i,costs[i]))

        iraw = 0
        if options.Display: ion(); clf()
        if db is not None:
            # for i in range(len(r.segs)): print "%6d %-8s %s"%(i,r.segs[i],r.output_l[i])
            line = ocrolib.read_image_gray(ocrolib.ffind(fname,"png"))
            line = amax(line)-line
            lgeo = docproc.seg_geometry(rseg)
            grouper = ocrolib.Grouper()
            grouper.setSegmentation(rseg)
            for i in range(grouper.length()):
                raw,mask = grouper.extractWithMask(line,i,dtype='B')
                start = grouper.start(i)
                end = grouper.end(i)
                bbox = grouper.boundingBox(i)
                y0,x0,y1,x1 = bbox
                rel = docproc.rel_char_geom((y0,y1,x0,x1),lgeo)
                ry,rw,rh = rel
                assert rw>0 and rh>0
                if (start,end) in r.segs:
                    index = r.segs.index((start,end))
                    cls = r.output_l[index]
                    cost = r.costs[index]
                else:
                    cls = "~"
                    cost = 0.0
                if options.debug_cls is not None and re.match(options.debug_cls,cls):
                    print "debug",start,end,"cls",cls,"cost",cost,\
                        "y %.2f w %.2f h %.2f"%(rel[0],rel[1],rel[2])
                if options.Display:
                    iraw += 1
                    subplot(options.dgrid,options.dgrid,iraw)
                    gray(); imshow(raw)
                    ax = gca()
                    ax.text(0.1,0.1,"%s"%cls,transform=ax.transAxes,color='red')
                dbhelper.dbinsert(db,"chars",
                               image=dbhelper.image2blob(raw),
                               cost=float(cost),
                               cls=cls,
                               count=1,
                               file= fname,
                               lgeo="%g %g %g"%lgeo,
                               rel="%g %g %g"%rel,
                               bbox="%d %d %d %d"%bbox)
        if options.Display: ginput(1,100)
    except IOError,e:
        print "# not found:",e
    except:
        if not options.cont: raise
        traceback.print_exc()
    if db is not None:
        db.commit()


jobs = []

if options.pagegt:
    if len(args)==1 and os.path.isdir(args[0]):
        args = glob.glob(args[0]+"/*.gt.txt")
    for arg in args:
        if not os.path.exists(arg):
            print "# %s: not found"%arg
            continue
        base,_ = ocrolib.allsplitext(arg)
        if not os.path.exists(base) or not os.path.isdir(base):
            print "["+base+"?]"
            sys.stdout.flush()
            continue
        lines = glob.glob(base+"/??????.png")
        for line in lines:
            jobs.append((line,arg))
    print
elif options.langmod:
    for arg in args:
        jobs.append((arg,options.langmod))
elif options.gt is not None:
    if len(args)==1 and (os.path.isdir(args[0]) or os.path.islink(args[0])):
        args = glob.glob(args[0]+"/????/??????.png")
    for arg in args:
        path,ext = ocrolib.allsplitext(arg)
        p = path+options.gt
        if not os.path.exists(arg):
            print arg,"not found"
            continue
        if not os.path.exists(p): 
            print p,"not found"
            continue
        jobs.append((arg,p))
else:
    raise Exception("you need to specify what kind of groundtruth you want to align with (-p, -l, -g)")

if options.parallel<2:
    for arg in jobs: align1(arg)
else:
    pool = Pool(processes=options.parallel)
    result = pool.map(safe_align1,jobs)
