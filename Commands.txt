(This file is generated by ./ocroex-gendoc.)


Usage: 
usage: 
ocropus-align [-s gt] [-l langmod] [options] file.fst ...

    Align each file.fst with language model and output the result into
    file.cseg.png, file.costs, and file.txt.  With -s gt, writes the
    results into file.cseg.gt.png, file.gt.costs, and file.gt.txt 
    instead.

ocropus-align [-s gt] [-g extension] [options] *.fst

    Align with groundtruth files.  For each x.fst, looks for the ground truth
    in x.extension

ocropus-align [-s gt] [-p] [options] *.gt.txt

    Align with page-level ground truth.  For each page.gt.txt, looks in
    page/??????.png for the image data.

Aligns recognition lattices (stored in .fst files) with language models and/or
ground truth.  If -g extension is given, each foo.fst file is aligned with a
corresponding foo.extension file.  

Language models and ground truth files may be given either as FST files or 
text files.  If they are given as text files, an FST is constructed by using
the fstutils.add_line_to_fst function.



Options:
  -h, --help            show this help message and exit
  -l LANGMOD, --langmod=LANGMOD
                        language model
  -x EXTRACT, --extract=EXTRACT
                        extract characters
  -X, --noextract       don't actually write files
  -L, --ligatures       output ligatures in aligned text
  -B BEAM, --beam=BEAM  size of beam
  -N, --noligatures     don't expand ligature notation in transcriptions
  -g GT, --gt=GT        extension for ground truth
  -p, --pagegt          arguments are page ground truth
  -s SUFFIX, --suffix=SUFFIX
                        output suffix for writing result
  -O, --overwrite       overwrite outputs
  -Q PARALLEL, --parallel=PARALLEL
                        number of parallel processes to use
  -P PERC, --perc=PERC  percentile for reporting statistics
  -M MAXPERC, --maxperc=MAXPERC
                        maximum cost at percentile
  -A MAXAVG, --maxavg=MAXAVG
                        maximum average cost



Usage: 
ocropus-binarize -o dir [options] image1 image2 ...

Performs preprocessing on each of the images on the command line and stores
the resulting output in a directory with "book structure".  That is, the
input pages will be stored in dir/0001.png dir/0001.bin.png dir/0002.png
dir/0002.bin.png etc.  dir/0001.png contains the deskewed grayscale image,
while dir/0001.bin.png contains the binarized version.

Preprocessing uses hysteresis thresholding; you control it mainly through the
-L and -H arguments, which take values between 0 and 1:

* large parts of characters are missing: decrease -H
* there is too much noise in the image: increase -H
* characters are too thin or broken up: increase -L
* characters are too thick or touching: decrease -L


Options:
  -h, --help            show this help message and exit
  -o OUTPUT, --output=OUTPUT
                        output directory
  -O, --Output          output image.png to image.bin.png (in place)
  -d, --display         display result
  -D, --Display         display continuously
  -T THRESHOLD, --threshold=THRESHOLD
                        threshold (simple Sauvola if set)
  -L LOW, --low=LOW     low threshold (0.1)
  -H HIGH, --high=HIGH  high threshold (0.4)
  -W WIDTH, --width=WIDTH
                        width parameter (40)
  -r DPI, --dpi=DPI     resolution (DPI) (300)
  -q, --silent          disable warnings
  -P PARALLEL, --parallel=PARALLEL
                        number of parallel processes to use
  -B BINARIZER, --binarizer=BINARIZER
                        binarization component to be used
  -g GTEXTENSION, --gtextension=GTEXTENSION
                        ground truth extension for copying in ground truth
                        (include all dots)



Usage: 
ocropus-cdistort [options] -o output.cmodel input.db ...



Options:
  -h, --help            show this help message and exit
  -L LIMIT, --limit=LIMIT
                        max # characters to load
  -N NVARIANTS, --nvariants=NVARIANTS
                        number of variants to generate
  -M MARGIN, --margin=MARGIN
                        degradation margin
  -D DISTORTION, --distortion=DISTORTION
                        maximum distortion
  -d, --display         debug display



Usage: 
ocropus-cedit [options] [input.db]

Edit character- and cluster-databases.

OCRopus isolated character training data is stored in sqlite3 databases
with a simple structure.  Isolated characters are (usually) stored in
a table called "chars", while clusters are stored in a table called
"clusters".  This application lets you browse and label these characters
and clusters.

You need to specify the correct table name for your database using the "-t"
flag.

Updates to the database are transacted and happen immediately; you don't need
to save.  Even concurrent editing and viewing is possible.  There is no
undo, but it's usually easy to manually undo changes.

There is a variety of sorting, training, and classification options available.
Particularly useful is the ability to sort by size and aspect ratio to quickly 
identify characters that have implausible sizes or aspect ratios.  Once you have
a character model, you can also sort by classifier confidence and focus correction
efforts on the characters with the least confidence.

Eventually, you will be able to cluster and train right from this interface, but
for now, use the external ocropus-ctrain and ocropus-cluster-db programs.



Options:
  -h, --help            show this help message and exit
  -m MODEL, --model=MODEL
                        model used for classification
  -v, --verbose         verbose
  -t TABLE, --table=TABLE
                        which table to edit
  -F, --flip            flip characters before handing to classifier
  -B BATCHSIZE, --batchsize=BATCHSIZE
                        maximum number of characters loaded for display
  -s SELECT, --select=SELECT
                        initial character to select



Usage: 
usage: ocropus-chargen [options] ...

Generates characters from TrueType fonts and stores them in a character database.


Options:
  -h, --help            show this help message and exit
  -o OUTPUT, --output=OUTPUT
                        output file
  -D, --display         display chars
  -r, --rel             output geometry information
  -R, --record          record parameter info in database
  -v, --verbose         verbose output
  -c CLASSES, --classes=CLASSES
                        list of classes (one per line)
  -s SIZES, --sizes=SIZES
                        list of sizes (Python expression)
  -f SPECS, --specs=SPECS
                        list of font specs
  -n NVARIANTS, --nvariants=NVARIANTS
                        number of variants
  -Q PARALLEL, --parallel=PARALLEL
                        number of parallel processes
  -e EVAL, --eval=EVAL  evaluate expressions (for additional options)
  -i INNER, --inner=INNER
                        inner offset for degradation (<1: some broken chars)



Usage: 
usage: ocropus-cluster-eps [options] chars.db cluster.db

Perform fast clustering of characters in a database using a fixed distance
measure.  The resulting cluster databases are often small enough to be 
labeled directly, or they can be clustered further using k-means.

This also updates the cluster id of the char in the original char.db to the id
of the corresponding cluster.


Options:
  -h, --help            show this help message and exit
  -D, --display         display chars
  -v, --verbose         verbose output
  -t TABLE, --table=TABLE
                        table name
  -e EPSILON, --epsilon=EPSILON
                        epsilon
  -o, --overwrite       overwrite output if it exists



Usage: 
usage: ocropus-cluster-kmeans [options] chars.db clusters.db

Perform kmeans clustering of characters in a database.  This is fairly slow, loads
all characters into memory, and can't be applied to big databases.  It is usually
applied after epsilon clustering if a further reduction in size is desired.


Options:
  -h, --help            show this help message and exit
  -D, --display         display chars
  -v, --verbose         verbose output
  -t TABLE, --table=TABLE
                        table name
  -k K, --k=K           k
  -m MINVECS, --minvecs=MINVECS
                        minimum number of vectors in a cluster
  -M MINCHANGE, --minchange=MINCHANGE
                        minimum number of changes (fraction)
  -n NITER, --niter=NITER
                        max number of iterations
  -O OUTLIER, --outlier=OUTLIER
                        outlier range



Usage: 
ocropus-ctrain [options] -o output.cmodel input.db ...

Trains models based on a cluster database.

For faster speed and better memory usage, use the "-b" option, which buffers
samples in a 1bpp buffer (only binary input patterns); however, this only works
with binary inputs and feature extractors that generate (approximately) binary
data.  For example, it works for binary character images and ScaledExtractor, but not
if you use grayscale character images or StandardExtractor.

If you have lots of training data, try "-E ScaledFeatureExtractor -b", for handwriting
recognition, "-E StandardExtractor" is a better choice.

You can choose different kinds of feature extractors with the -E flag.  
Some possible values are: ScaledExtractor (raw grayscale image rescaled to a target size) 
and BiggestCcExtractor (biggest connected component only, otherwise treated like scaledfe).
You can find additional components by running "ocropus components" and looking for
implementors of IExtractor.

Common parameters for the model are:

-m '=ocrolib.mlp.AutoMlpModel()'


Options:
  -h, --help            show this help message and exit
  -o OUTPUT, --output=OUTPUT
                        output model name
  -m MODEL, --model=MODEL
                        IModel name
  -b, --bits            buffer training data with 1 bpp
  -t TABLE, --table=TABLE
                        database table to use for training
  -r, --noreject        disable reject class
  -u, --unlabeled       treat unlabeled ('_') as reject
  -n LIMIT, --limit=LIMIT
                        limit training to n samples
  -1, --single          train only single chars
  -v, --verbose         verbose
  -E EXTRACTOR, --extractor=EXTRACTOR
                        feature extractor
  -N NVARIANTS, --nvariants=NVARIANTS
                        number of variants to generate
  -D DISTORTION, --distortion=DISTORTION
                        maximum distortion
  -d, --display         debug display
  -g, --nogeometry      do not add geometric information
  -M MINPERCLASS, --minperclass=MINPERCLASS
                        min # samples per class
  -P PERCLASSLIMIT, --perclasslimit=PERCLASSLIMIT
                        max # of samples per class
  -R REJECTLIMIT, --rejectlimit=REJECTLIMIT
                        max # of samples for the reject class
  -Q MAXTHREADS, --maxthreads=MAXTHREADS
                        max # of threads for training



Usage: 
ocropus-dbclass [options] input.db 

Apply a classifier to the characters in the database and store the classification
results in the database.

By default, stores the classification results in separate columns, pred and pcost.
The cost of the actual character in cls is stored in pocost.  An overall error
rate is returned.  If -e is given, only computes the error rate but stores nothing.

Alternatively, can update the cls and cost columsn in the database themselves
when the -C option is given.  This is useful, for example, on the output from
ocropus-extract-rseg or clustered output.


Options:
  -h, --help            show this help message and exit
  -D, --display         display the characters
  -e, --error           only calculate error
  -C, --setclass        set class, not pred
  -N LIMIT, --limit=LIMIT
                        max # samples
  -m MODEL, --model=MODEL
                        model used for classification
  -t TABLE, --table=TABLE
                        table



Usage: 
usage: ocropus-dbinfo [options] database.db ...

Show information about the given databases.


Options:
  -h, --help  show this help message and exit
  -f, --full  full class counts



Usage: 
usage: ocropus-extract [options] .../.../010001.png ...

Extract character images from text line image files using the cseg files
left by the recognizer; character images are labeled by their corresponding 
characters in the .txt files.  

You must run ocropus-lattices and ocropus-align first to obtain the cseg 
and txt files.  You can also manually create the cseg and txt files.


Options:
  -h, --help            show this help message and exit
  -G GTSUFFIX, --gtsuffix=GTSUFFIX
                        ground truth suffix
  -g, --nogeo           don't extract geometry
  -o OUTPUT, --output=OUTPUT
                        output file
  -u UNMERGED, --unmerged=UNMERGED
                        unmerged output file
  -n, --nomissegmented  output no missegmented characters
  -r, --raw             output unlabeled characters
  -a MAXAGE, --maxage=MAXAGE
                        output missegmented
  -D, --display         display chars
  -v, --verbose         verbose output
  -N, --nosource        do not record source info
  -c, --cont            continue even if errors are found
  -E EXTRACOST, --extracost=EXTRACOST
                        cost for misaligned characters
  -P PERC, --perc=PERC  cost percentile
  -M MAXPERC, --maxperc=MAXPERC
                        maximum cost at percentile
  -A MAXAVG, --maxavg=MAXAVG
                        maximum average cost



Usage: 
usage: ocropus-extract-rsegs [options] .../.../010001.png ...

Extract character images from raw text line files.  This uses a segmenter
to get character candidates.  No model is used, instead it uses a connected
component segmenter that will yield a lot of good characters on normal quality
input data.

Afterwards, it's useful to run a clustering step (ocropus-cluster-*) or a
classification step (ocropus-dbclass).  Then, the images can be classified
and edited in ocropus-cedit.


Options:
  -h, --help            show this help message and exit
  -o OUTPUT, --output=OUTPUT
                        output file
  -d DISPLAY, --display=DISPLAY
                        display characters
  -v VERBOSE, --verbose=VERBOSE
                        verbose output
  -m MINSIZE, --minsize=MINSIZE
                        minimum component width and height
  -a, --absolute        output absolute images
  -s SEGMENTER, --segmenter=SEGMENTER
                        segmenter
  -n N, --n=N           maximum number of chars
  -N, --nosource        do not record source info



Usage: 
ocropus-gated-load -o gated.model input1.model input2.model ...

Combine classifiers into a gated model.  Classifiers with a corresponding .info
file are gated, while other classifiers are used unconditionally.


Options:
  -h, --help            show this help message and exit
  -c CUTOFF, --cutoff=CUTOFF
                        cutoff
  -o OUTPUT, --output=OUTPUT
                        ouptut file



Usage: 
ocropus-gated-train [options] input.db dir

Perform training of gated models.


Options:
  -h, --help            show this help message and exit
  -C CACHESIZE, --cachesize=CACHESIZE
                        number of characters to be cached (1M approx 8Gbyte)
  -c CUTOFF, --cutoff=CUTOFF
                        cutoff used for gating
  -m MODEL, --model=MODEL
                        starter model
  -D, --display         display
  -N LIMIT, --limit=LIMIT
                        limit training
  -S NSAMPLE, --nsample=NSAMPLE
                        numer of samples for estimation
  -r ROUNDS, --rounds=ROUNDS
                        mlp rounds
  -n NTRAIN, --ntrain=NTRAIN
                        ntrain
  -t TABLE, --table=TABLE
                        table
  -T THRESHOLD, --threshold=THRESHOLD
                        cutoff
  -o OUTPUT, --output=OUTPUT
                        ouptut file



Usage: 
ocropus-hocr [options] book/????.png

Puts together the result of OCR steps into an XHTML output file.
Uses...

book/0001.png                # page image
book/0001.bin.png            # binarized page image
book/0001.pseg.png           # page segmentation
book/0001/010001.txt         # recognizer output for lines
book/0001/010001.cseg.png    # character segmentation for lines

etc.


Options:
  -h, --help    show this help message and exit
  -b, --breaks  output line breaks



Usage: 
usage: ocropus-lattices [options] image1.png image2.png ...

Computes recognition lattices for text lines.  Also displays the bestpath
result (recognition result without language model).


Options:
  -h, --help            show this help message and exit
  -m MODEL, --model=MODEL
                        model file
  -w WHITESPACE, --whitespace=WHITESPACE
                        space model file
  -c, --cont            continue even when unexpected errors occur
  -R MAXRANGE, --maxrange=MAXRANGE
                        max range for grouping
  -L, --noligatures     don't output ligatures
  -N NBEST, --nbest=NBEST
                        use the nbest results from classifier
  -C MAXCOST, --maxcost=MAXCOST
                        maximum cost to be considered
  -s SEGMENTER, --segmenter=SEGMENTER
                        segmenter
  -S SUFFIX, --suffix=SUFFIX
                        suffix for writing rseg/cseg files
  -O, --overwrite       overwrite rseg/cseg files
  -Q PARALLEL, --parallel=PARALLEL
                        number of parallel processes to use
  -d, --display         display progress



Usage: 
usage: ocropus-linefst text.txt langmod.fst



Options:
  -h, --help  show this help message and exit



Usage: 
ocropus-pages [options] image1 image2 ...

IMPORTANT: This is not the preferred way of running OCRopus.  Instead,
use the ocropus-{binarize,pseg,lattice,align,hocr} commands.

===

Recognize pages using built-in OCRopus components.  This first
uses the page cleaner, then the page segmenter, then the line
recognizers, and finally the language model.

The following components take files as arguments, and those files
are loaded in various ways.

--linerec -- line recognizer (.pymodel, .cmodel, or .model)
--langmod -- language model (OpenFST language model dump)

If you want to see what's going on, run ocropus-pages with the "-d" option
("-D" for continuous output, but this slows down recognition significantly).
With the "-L" option, you also see each text line as it's being recognized.

(For even more insight into what is going on during recognition, use the
ocropus-showpsegs and ocropus-showlrecs commands.)

Advanced Usage:

You can choose from a number of components for the different
processing stages.  See the output of "ocropus components" for your
choices.

Possible choices are:

--clean (ICleanupGray) -- binarization, denoising, deskewing
--pseg (ISegmentPage) -- page segmentation
--ticlass (ITextImageSegmentation) -- text/image segmentation (off by default)

For each component, you can pass additional parameters.  For example,
--clean StandardPreprocessing:rmbig_minaspect=0.1 uses an instance of
StandardPreprocessing for cleanup and sets its rmbig_minaspect
parameter to 0.1.  You can see a list of all the parameters with
"ocropus params StandardPreprocessing".

Instead of component names, you can also pass the names of
constructors of Python classes for each of those components, as in
"--clean my.CleanupPage:threshold=0.3" or "--clean
my.CleanupPage(0.3)".  This will import the "my" package and then call
the constructor.


Options:
  -h, --help            show this help message and exit
  -C CLEAN, --clean=CLEAN
                        page cleaner
  -P PSEG, --pseg=PSEG  line segmenter
  -T TICLASS, --ticlass=TICLASS
                        text image segmenter
  -m LINEREC, --linerec=LINEREC
                        linerec model
  -l LANGMOD, --langmod=LANGMOD
                        langmod
  -w LWEIGHT, --lweight=LWEIGHT
                        weight for the language model
  -v, --verbose         verbose
  -x, --hocr            output XHTML+hOCR
  -p, --plain           output plain text
  -r DPI, --dpi=DPI     resolution in dpi
  -S, --silent          disable warnings
  -d, --display         display result
  -D, --Display         display continuously
  -L, --displaylines    display lines as well
  -B BEAM, --beam=BEAM  size of beam in beam search



Usage: 
ocropus-pseg [options] image1.png image2.png ...

Usually, you would use an argument pattern like: book/????/??????.png

Computes page segmentations and extracts text lines.
For each input image image.png, it generates:

* image.pseg.png -- page segmentation
* image/010001.png -- gray scale text line image column 1, line 1
* image/010001.bin.png -- bineary text line image column 1, line 1

Use the -d or -D argument to verify that the layout analysis is working
correctly.

If image.bin.png exists, it uses it.  If not, it uses built-in
preprocessing and generates and writes its own binary version.
(The original gray scale image is, however, not altered, so it
may be rotated relative to the binary image.)

If an image.tiseg.png file exists, it uses it to constrain the
layout analysis (although some layout analysis methods may be
ignoring the map).


Options:
  -h, --help            show this help message and exit
  -g, --gray            output grayscale images + binary masks
  -u UPSCALE, --upscale=UPSCALE
                        upscale lines shorter than this to the given target
                        height
  -t TARGET, --target=TARGET
                        downscale lines taller than this to the given target
                        height
  -L LOW, --low=LOW     lower limit for text line height
  -H HIGH, --high=HIGH  upper limit for text line height
  -W WIDTH, --width=WIDTH
                        lower limit for text line width
  -v, --verbose         output additional information
  -p PAD, --pad=PAD     pad lines by this amount
  -d, --display         display result
  -D, --Display         display continuously
  -S SEGMENTER, --segmenter=SEGMENTER
                        which segmentation component to use
  -P PREPROC, --preproc=PREPROC
                        which preprocessing component to use
  -r DPI, --dpi=DPI     resolution of input image in DPI
  -q, --silent          disable warnings
  -b, --blackout        use blackout for image regions (instead of passing
                        rectangles)
  -R DESCENDER, --descender=DESCENDER
                        maximum descender
  -Q PARALLEL, --parallel=PARALLEL
                        number of parallel processes to use



Usage: 
ocropus-showlrecs [options] line1.png line2.png ...

Interactively explore line recognition and line recognition errors.


Options:
  -h, --help            show this help message and exit
  -v, --verbose         verbose
  -s, --spaces          count spaces
  -c, --case            case sensitive
  -B NBEST, --nbest=NBEST
                        nbest chars
  -M MAXCCOST, --maxccost=MAXCCOST
                        maxcost for characters in recognizer
  -b BEAM, --beam=BEAM  beam width
  -R RECOGNIZER, --recognizer=RECOGNIZER
                        line model
  -L LANGMOD, --langmod=LANGMOD
                        language model



Usage: 
ocropus-showpsegs [options] [input.db]

Trains models based on a cluster database.


Options:
  -h, --help     show this help message and exit
  -v, --verbose  verbose



Usage: 
ocropus-tiseg [options] page1.png page2.png ...

Computes text/image segmentation of grayscale input images.


Options:
  -h, --help            show this help message and exit
  -d, --display         display result
  -D, --Display         display continuously
  -r DPI, --dpi=DPI     resolution in DPI
  -c CLOSE, --close=CLOSE
                        closing
  -o OPEN, --open=OPEN  opening
  -S SEGMENTATION, --segmentation=SEGMENTATION
                        segmentation component



Usage: 
usage: ocropus-wtrain [options] .../.../010001.png ...

Train whitespace classifiers on the given text line images.  Uses the corresponding
cseg and txt files for training.  All training samples are loaded into memory.


Options:
  -h, --help            show this help message and exit
  -o OUTPUT, --output=OUTPUT
                        output file
  -s SUFFIX, --suffix=SUFFIX
                        suffix for cseg and txt files
  -v, --verbose         verbose output
  -c, --cerrors         continue even if errors are found
  -D, --display         display chars

